{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/114.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "BIG5_URL = (\n",
    "    \"https://fbref.com/en/comps/Big5/stats/players/\"\n",
    "    \"Big-5-European-Leagues-Stats\"\n",
    ")\n",
    "\n",
    "def get_big5_player_list(url: str) -> pd.DataFrame:\n",
    "    resp = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # grab *all* comment strings and combine\n",
    "    comments = [c for c in soup.find_all(string=lambda t: isinstance(t, Comment))]\n",
    "    comment_html = \"\\n\".join(comments)\n",
    "    comment_soup = BeautifulSoup(comment_html, \"html.parser\")\n",
    "\n",
    "    # locate the main table\n",
    "    table = comment_soup.find(\"table\", id=\"stats_standard\")\n",
    "    if table is None:\n",
    "        raise RuntimeError(\"Could not find #stats_standard in comments\")\n",
    "\n",
    "    players = []\n",
    "    for tr in table.tbody.find_all(\"tr\"):\n",
    "        td = tr.find(\"td\", {\"data-stat\": \"player\"})\n",
    "        if not td or not td.a:\n",
    "            continue\n",
    "        name = td.a.text.strip()\n",
    "        href = td.a[\"href\"]\n",
    "        players.append({\n",
    "            \"name\": name,\n",
    "            \"url\": \"https://fbref.com\" + href\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_per90(url: str) -> dict | None:\n",
    "    resp = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    # combine rendered + commented HTML\n",
    "    comments = [c for c in soup.find_all(string=lambda t: isinstance(t, Comment))]\n",
    "    all_html = resp.text + \"\\n\" + \"\\n\".join(comments)\n",
    "    full_soup = BeautifulSoup(all_html, \"html.parser\")\n",
    "\n",
    "    # find any table with “Scouting Report” in its caption\n",
    "    target = None\n",
    "    for tbl in full_soup.find_all(\"table\"):\n",
    "        cap = tbl.find(\"caption\")\n",
    "        if cap and \"Scouting Report\" in cap.text:\n",
    "            target = tbl\n",
    "            break\n",
    "    if target is None:\n",
    "        return None\n",
    "\n",
    "    stats = {}\n",
    "    for tr in target.tbody.find_all(\"tr\"):\n",
    "        th = tr.find(\"th\", {\"data-stat\": \"statistic\"})\n",
    "        td = tr.find(\"td\", {\"data-stat\": \"per90\"})\n",
    "        if not th or not td:\n",
    "            continue\n",
    "\n",
    "        key = th.text.strip()\n",
    "        val = td.text.strip().replace(\"%\", \"\")\n",
    "        try:\n",
    "            stats[key] = float(val)\n",
    "        except ValueError:\n",
    "            stats[key] = None\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_per90(big5_url: str, pause: float = 2.0) -> pd.DataFrame:\n",
    "    df_players = get_big5_player_list(big5_url)\n",
    "    all_data = []\n",
    "    for row in df_players.itertuples():\n",
    "        print(f\"→ Scraping {row.name} …\", end=\"\")\n",
    "        stats = extract_player_per90(row.url)\n",
    "        if stats:\n",
    "            stats[\"Player\"] = row.name\n",
    "            all_data.append(stats)\n",
    "            print(\" OK\")\n",
    "        else:\n",
    "            print(\" no scouting table\")\n",
    "        time.sleep(pause)\n",
    "\n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not find #stats_standard in comments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_all \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_all_per90\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBIG5_URL\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m, in \u001b[0;36mscrape_all_per90\u001b[0;34m(big5_url, pause)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_all_per90\u001b[39m(big5_url: \u001b[38;5;28mstr\u001b[39m, pause: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m----> 2\u001b[0m     df_players \u001b[38;5;241m=\u001b[39m \u001b[43mget_big5_player_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbig5_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     all_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df_players\u001b[38;5;241m.\u001b[39mitertuples():\n",
      "Cell \u001b[0;32mIn[14], line 31\u001b[0m, in \u001b[0;36mget_big5_player_list\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     29\u001b[0m table \u001b[38;5;241m=\u001b[39m comment_soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats_standard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find #stats_standard in comments\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m players \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mtbody\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not find #stats_standard in comments"
     ]
    }
   ],
   "source": [
    "df_all = scrape_all_per90(BIG5_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
